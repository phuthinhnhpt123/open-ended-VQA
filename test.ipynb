{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'visual7w'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 347.61it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 23.19it/s]\n",
      "Generating train split: 28653 examples [00:02, 10340.18 examples/s]\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"json\", data_files=os.path.join(data_dir, \"dataset_v7w_telling.json\"), field=\"images\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 28653/28653 [00:02<00:00, 12820.24 examples/s]\n",
      "Filter: 100%|██████████| 28653/28653 [00:02<00:00, 10482.72 examples/s]\n",
      "Filter: 100%|██████████| 28653/28653 [00:02<00:00, 10687.06 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = data.filter(lambda x: x['split'] == 'train')\n",
    "test_dataset = data.filter(lambda x: x['split'] == 'test')\n",
    "val_dataset = data.filter(lambda x: x['split'] == 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(dataset):\n",
    "    questions = []\n",
    "    answers = []\n",
    "    image_id = []\n",
    "    types = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        qa_pairs = dataset[i]['qa_pairs']\n",
    "        for j in range(len(qa_pairs)):\n",
    "            questions.append(qa_pairs[j]['question'])\n",
    "            answers.append(str(qa_pairs[j]['answer']).strip('.'))\n",
    "            types.append(qa_pairs[j]['type'])\n",
    "            image_id.append(dataset[i]['filename'])\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'questions': questions,\n",
    "        'answers': answers,\n",
    "        'image_id': image_id,\n",
    "        'types': types\n",
    "    })\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = preprocess(train_dataset)\n",
    "data_train.to_csv(\"visual7w/train.csv\", index=False)\n",
    "\n",
    "data_test = preprocess(test_dataset)\n",
    "data_test.to_csv(\"visual7w/test.csv\", index=False)\n",
    "\n",
    "data_val = preprocess(val_dataset)\n",
    "data_val.to_csv(\"visual7w/val.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"visual7w/train.csv\")\n",
    "data_test = pd.read_csv(\"visual7w/test.csv\")\n",
    "data_val = pd.read_csv(\"visual7w/val.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what question has 33293 samples\n",
      "where question has 11421 samples\n",
      "how question has 10305 samples\n",
      "who question has 7075 samples\n",
      "why question has 4470 samples\n",
      "when question has 3253 samples\n"
     ]
    }
   ],
   "source": [
    "for type in [\"what\", \"where\", \"how\", \"who\", \"why\", \"when\"]:\n",
    "    sub_dataset = data_train[data_train['types'] == type]\n",
    "    print(f\"{type} question has {len(sub_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"questions\": [], \"answers\": [], \"image_id\": [], \"types\": []}\n",
    "sample = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for type in [\"what\", \"where\", \"how\", \"who\", \"why\", \"when\"]:\n",
    "    sub_dataset = data_val[data_val['types'] == type]\n",
    "\n",
    "    sub_sample = sub_dataset.sample(n=int(len(sub_dataset)*0.25))\n",
    "\n",
    "    sample = pd.concat([sample,sub_sample],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"visual7w/sample_1_4/sample_train.csv\")\n",
    "data_test = pd.read_csv(\"visual7w/sample_1_4/sample_test.csv\")\n",
    "data_val = pd.read_csv(\"visual7w/sample_1_4/sample_val.csv\")\n",
    "\n",
    "data_augment = pd.read_csv(\"visual7w/augment/augment.csv\")\n",
    "\n",
    "train = pd.read_csv(\"visual7w/original/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_in = pd.merge(data_augment,data_train[['questions','answers']], on=['questions','answers'], how='left', indicator=True)\n",
    "df_not_in = df_not_in[df_not_in['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "df_not_in = df_not_in.drop_duplicates(ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_need_add = train.merge(df_not_in[['questions', 'answers']], on=['questions', 'answers'], how='inner',indicator=True)\n",
    "df_need_add = df_need_add[df_need_add['_merge'] == 'both'].drop(columns='_merge')\n",
    "df_need_add = df_need_add.drop_duplicates(ignore_index=True)\n",
    "df_need_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.concat([data_train,df_need_add],ignore_index=True)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = [\"what\", \"where\", \"how\", \"who\", \"why\", \"when\"]\n",
    "\n",
    "tmp['types'] = pd.Categorical(tmp['types'], categories=order, ordered=True)\n",
    "\n",
    "df_sorted = tmp.sort_values('types',ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.to_csv(\"visual7w/sample_1_4/sample_train.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 1\n",
    "for i in range(len(data_augment)):\n",
    "    data_augment.loc[i,'image_id'] = f\"gen{counter}.jpg\"\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augment.to_csv(\"visual7w/augment/augment.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
